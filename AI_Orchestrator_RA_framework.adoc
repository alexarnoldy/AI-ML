:Author: Alex Arnoldy
:AuthorEMail: Alex.Arnoldy@SUSE.com

:CompanyName: SUSE
:ProductName: AI Orchestrator
:ProductNameCaaSP: CaaS Platform
:ProductNameSES: Enterprise Storage

:IHVPartner: Dell
:IHVNetwork: NotApplicable
:IHVPlatform: PowerEdge 
:IHVPlatformComposer: NotApplicable
:IHVPlatformComposerTech: NotApplicable
:IHVPlatformImager: NotApplicable
:IHVPlatformModel: R740xd
:IHVPlatformBMC: iDRAC

:MarketCategory: Artifical Intelligence / Machine Learning
:MarketCategoryAbbreviation: AI/ML

= Reference Configuration: {CompanyName} {ProductName} with {IHVPartner} {IHVPlatform}
{Author}, {CompanyName} < {AuthorEMail} >

== Executive Summary
This reference configuration is designed to help organizations understand and take full advantage of the SUSE {ProductName} to manage workloads run on an {MarketCategory} framework. While SUSE {productname} can manage multiple {marketcategoryabbreviation} frameworks, both on-premise and in any cloud provider, this document focuses on using {productname} to manage Kubeflow running on {productnamecaasp}. This document provides an archtitectural overview and value anaylsis for using {productname} to manage the work of adapting and running ML analysis model pipelines a production-ready Kubeflow deployment. Finally, it provides design considerations, implementation suggestions and best practices.

For most enterprise-level businesses, the demand for {marketcategoryabbreviation} projects is increasing rapidly. As with any cutting edge technology, inititives can quickly bogged down in cumbersome tasks managing the https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf[Hidden Technical Debt of Machine Learning Systems]. Fortunately, {marketcategoryabbreviation} projects have a well defined decipline in the world of DevOps to follow. As in the DevOps world, one of the most important keys to success in many {marketcategory} projects is leveraging technologies that minimize manual intervention and maximize repeatability.

Implementing an intelligent, automation-focused management layer, such as {productname} enables you to transform your {marketcategoryabbreviation} from requiring an almost impossible to define number of manual steps into a clearly defined effort with diciplined and repeatable steps and milestones. In addition, the SUSE {productname} enables AI Operations teams to track and influence the resources expended on {marketcategoryabbreviation} projects and even individual analysis runs. 

== Target Audience
This document is intended for IT decision makers, architects, data scientists and AI operators who are implementing an ever increasing number of {marketcategoryabbreviation} projects; and struggling under the friction of bringing {marketcategoryabbreviation} models from design to revenue generating production.  You should be familiar with the traditional IT infrastructure pillars—networking, computing and storage—along with key concepts in the field of developing, testing, and deploying {marketcategory} predictive models.

== Solution Overview
When SUSE set out to create a new, indispensible {marketcategoryabbreviation} tool for its customers, we were certain that we didn't want to create just another framework/training/analysis tool. What the wild west of {marketcategoryabbreviation} needs more than anything else is a tool that returns control of the tools to the AI consumer and improves the chances of success for every AI/ML project.

From the outset, in creating the SUSE {productname} we followed several primary guidelines: 
* Enable Data Scientists to stay focused on the creative end of data model design and development
* Significantly improve the visibility and control of the AI Platforms, as well as the expendatures that go with them, to the AI Operations teams
* Improve cross team visibility and enable new avenues of collaboration between Data Scientists, AI Engineers, and AI Operators
* Enable model pipeline execution on virtually any platform, from a single workstation, to Kubeflow, to any public cloud provider; all without having to rewrite any part of the model or pipeline definition.


As an {marketcategoryabbreviation} pipeline development and management tool, the SUSE {productname} has the ability to manage operations on multiple platforms. With its large community of developers and a plethora of features and capabilities, the he initial focus of the {productname} is Kubeflow running on SUSE {productnamecaasp}. 


== Solution Components

=== Facility
SUSE {productname} is a fully containerized Linux application and thus can run on any platform that is configured to run Linux containers. While a small data science team may choose to run the {productname} on a workstation, most customers will likely prefer to run it within a highly resilient container ochestrator, such as SUSE {productnamecaasp}.

=== {marketcategoryabbreviation} Platform
Kubeflow is a open-source machine learning platform that enables running machine learning projects on a highly resilient and scalable Kubernetes platform. Kubeflow is actually a collection of nearly a dozen different {marketcategoryabbreviation} frameworks and tools including Jupyter Notebook, TensorFlow, and Pytorch. Being a Kubernetes application suite, the installation and initial configuration is deceptively simple; though the resultant set of applications is one of the most powerful in the industry.

=== {productnamecaasp} Platform
{CompanyName} {ProductName} is an enterprise-class container management solution that enables IT and DevOps professionals to more easily deploy, manage, and scale container-based applications and services. It includes Kubernetes to automate lifecycle management of modern applications and surrounding technologies that enrich Kubernetes and make the platform itself easy to operate. As a result, enterprises that use {CompanyName} {ProductName} can reduce application delivery cycle times and improve business agility.

{CompanyName} is focused on delivering an exceptional operator experience with {CompanyName} {ProductName}. With deep competencies in infrastructure, systems, process integration, platform security, lifecycle management and enterprise-grade support, {CompanyName} aims to ensure that IT operations teams can deliver the power of Kubernetes to their users quickly, securely and efficiently.

With {CompanyName} {ProductName} you can: * Achieve faster time to value with an enterprise-ready container management platform, built from industry-leading technologies, and delivered as a complete package — with everything you need to quickly offer container services. * Simplify management and control of your container platform with efficient installation, easy scaling, and update automation. * Maximize return on your investment, with a flexible container services solution for today and tomorrow.


=== Storage
Many of the Kubeflow applications leverage a large amount of highly available, highly resilient, persistent storage.
SUSE {productnamecaasp} can access both network block and object storage via the modular Container-Storage-Interface (CSI) technologies. 
One of the most popular storage solutions available for containerized workloads is SUSE {productnameses}, which is a Ceph-based, software-defined storage infrastructure. In addition to versatility, SUSE {productnameses} can scale into the dozens of petabytes while scaling linearly in performance.

NOTE: Such integrations, with solutions like {CompanyName} {ProductNameSES}, are detailed in other reference documents.

== Solution Details
This document focuses on the advanages of an {marketcategoryabbreviation} solution stack centered around the {CompanyName} {ProductName}.

This document focuses on a new {CompanyName} {ProductName} deployment which could be scaled over time. A starting point could be a single hypervisor host with virtual machines set up for each of the needed roles to create a basic, minimal cluster to simply evaluate functionality. Over time more physical nodes could be added to augment the cluster or to replace some of the initial, virtual-machine-based roles. To provide a production-ready cluster and take advantage of the {IHVPartner} {IHVPlatform} platform and it's composable features, the following figure shows the target logical cluster deployment:


== Conclusion
After understanding and working through the steps described in this document, you should have a working container-as-a-service platform that is scalable through the addition of even more resource nodes, as needed. {CompanyName} {ProductName} provides a complete suite of the necessary software and processes which leverages the composability aspect of {IHVPartner} {IHVPlatform} to create a production-worthy and agile platform for deployment of containerized microservice workloads.


== Resources and additional links
